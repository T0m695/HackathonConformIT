import os
import json
import boto3
from botocore.exceptions import ClientError
from dotenv import load_dotenv

# Ajout d'une constante pour les mod√®les d'embedding courants
# Vous devez activer l'acc√®s √† ce mod√®le dans la console AWS Bedrock.
TITAN_EMBEDDING_MODEL_ID = "amazon.titan-embed-text-v1" 

def _get_bedrock_client(aws_region: str, aws_access_key: str, aws_secret_key: str, aws_session_token: str = None):
    """
    Fonction utilitaire pour initialiser le client Bedrock Runtime.
    """
    session_config = {
        'service_name': 'bedrock-runtime',
        'region_name': aws_region,
        'aws_access_key_id': aws_access_key,
        'aws_secret_access_key': aws_secret_key,
    }
    
    if aws_session_token:
        session_config['aws_session_token'] = aws_session_token
        
    return boto3.client(**session_config)

def invoke_llm(prompt_text: str, model_id: str = "anthropic.claude-3-haiku-20240307-v1:0"):
    """
    Appelle un mod√®le LLM sur Amazon Bedrock avec le prompt donn√©.
    
    Args:
        prompt_text (str): Le texte de la requ√™te utilisateur.
        model_id (str): L'ID du mod√®le Bedrock √† utiliser (par d√©faut: Claude 3 Haiku).

    Returns:
        str: Le texte g√©n√©r√© par le LLM ou un message d'erreur.
    """
    
    # --- Configuration AWS ---
    aws_access_key = os.getenv("AWS_ACCESS_KEY_ID")
    aws_secret_key = os.getenv("AWS_SECRET_ACCESS_KEY")
    aws_session_token = os.getenv("AWS_SESSION_TOKEN") # Optionnel pour les sessions temporaires
    aws_region = os.getenv("AWS_DEFAULT_REGION", "us-east-1")
    
    if not aws_access_key or not aws_secret_key:
        return "‚ùå ERREUR: Les variables d'environnement AWS_ACCESS_KEY_ID et AWS_SECRET_ACCESS_KEY sont requises."

    # --- Initialisation du client Bedrock ---
    try:
        bedrock = _get_bedrock_client(aws_region, aws_access_key, aws_secret_key, aws_session_token)
        print(f"‚úÖ Client Bedrock initialis√© (R√©gion: {aws_region}, Mod√®le LLM: {model_id})")

    except Exception as e:
        return f"‚ùå ERREUR: Impossible d'initialiser le client AWS Bedrock: {str(e)}"

    # --- Pr√©paration du corps de la requ√™te (Format pour les mod√®les Anthropic Claude) ---
    body = json.dumps({
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 1000,
        "messages": [
            {
                "role": "user",
                "content": prompt_text
            }
        ],
        "temperature": 0.5
    })
    
    # --- Appel de l'API ---
    try:
        print("üîç Appel de l'API Bedrock LLM en cours...")
        response = bedrock.invoke_model(
            modelId=model_id,
            body=body
        )
        
        # --- Traitement de la r√©ponse ---
        response_body = json.loads(response['body'].read())
        
        if response_body and 'content' in response_body and response_body['content']:
            return response_body['content'][0]['text']
        else:
            return "‚ö†Ô∏è R√©ponse vide du mod√®le LLM."
            
    except ClientError as e:
        error_code = e.response.get('Error', {}).get('Code', 'Unknown')
        return f"‚ùå ERREUR AWS ({error_code}): {str(e)}"
    except Exception as e:
        return f"‚ùå ERREUR lors de l'appel au mod√®le LLM: {str(e)}"


def invoke_embedding_model(text_to_embed: str, model_id: str = TITAN_EMBEDDING_MODEL_ID):
    """
    Appelle un mod√®le d'embedding sur Amazon Bedrock pour obtenir un vecteur.
    
    Args:
        text_to_embed (str): Le texte √† convertir en embedding.
        model_id (str): L'ID du mod√®le d'embedding (par d√©faut: Titan G1 Text).

    Returns:
        list: Le vecteur d'embedding (liste de flottants) ou un message d'erreur.
    """
    
    # --- Configuration AWS ---
    aws_access_key = os.getenv("AWS_ACCESS_KEY_ID")
    aws_secret_key = os.getenv("AWS_SECRET_ACCESS_KEY")
    aws_session_token = os.getenv("AWS_SESSION_TOKEN")
    aws_region = os.getenv("AWS_DEFAULT_REGION", "us-east-1")
    
    if not aws_access_key or not aws_secret_key:
        return "‚ùå ERREUR: Les variables d'environnement AWS_ACCESS_KEY_ID et AWS_SECRET_ACCESS_KEY sont requises."

    # --- Initialisation du client Bedrock ---
    try:
        bedrock = _get_bedrock_client(aws_region, aws_access_key, aws_secret_key, aws_session_token)
        print(f"‚úÖ Client Bedrock initialis√© (R√©gion: {aws_region}, Mod√®le Embedding: {model_id})")

    except Exception as e:
        return f"‚ùå ERREUR: Impossible d'initialiser le client AWS Bedrock: {str(e)}"

    # --- Pr√©paration du corps de la requ√™te (Format pour Amazon Titan Text Embeddings) ---
    # Le format varie selon le mod√®le (ex: Cohere utilise 'texts' au lieu de 'inputText')
    body = json.dumps({
        "inputText": text_to_embed
    })
    
    # --- Appel de l'API ---
    try:
        print(f"üîç G√©n√©ration de l'embedding pour le texte: '{text_to_embed[:50]}...'")
        response = bedrock.invoke_model(
            modelId=model_id,
            body=body,
            contentType='application/json',
            accept='application/json'
        )
        
        # --- Traitement de la r√©ponse ---
        response_body = json.loads(response['body'].read())
        
        # Extrait l'embedding (liste de flottants)
        if response_body and 'embedding' in response_body:
            return response_body['embedding']
        else:
            return "‚ö†Ô∏è R√©ponse vide ou format incorrect du mod√®le d'embedding."
            
    except ClientError as e:
        error_code = e.response.get('Error', {}).get('Code', 'Unknown')
        return f"‚ùå ERREUR AWS ({error_code}): {str(e)}"
    except Exception as e:
        return f"‚ùå ERREUR lors de l'appel au mod√®le d'embedding: {str(e)}"

if __name__ == "__main__":
    
    load_dotenv()
    
    # 1. D√©finissez votre prompt ici
    llm_prompt = "Donne un code python pour diagonaliser une matrice numpy."
    embedding_text = "Quel est le produit le plus populaire en vente?"

    print(f"\n--- Requ√™te LLM Minimaliste ---")
    print(f"Prompt: '{llm_prompt}'")
    
    # 2. Appelez la fonction LLM et affichez la r√©ponse
    llm_response = invoke_llm(llm_prompt)
    
    print("\n--- R√©ponse du LLM ---")
    print(llm_response)
    print("-------------------------\n")
    
    # 3. Appel de la nouvelle fonction d'Embedding
    print(f"\n--- Calcul de l'Embedding ---")
    print(f"Texte √† emb√©dir: '{embedding_text}'")
    
    embedding_vector = invoke_embedding_model(embedding_text)
    
    print("\n--- R√©sultat de l'Embedding ---")
    if isinstance(embedding_vector, list):
        print(f"‚úÖ Vecteur d'embedding g√©n√©r√©. Dimension: {len(embedding_vector)}")
        print(f"Exemple des 5 premi√®res valeurs: {embedding_vector[:5]}")
    else:
        print(embedding_vector) # Affiche le message d'erreur
    print("-----------------------------\n")